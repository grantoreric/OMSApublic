{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import csv\n",
    "import numpy as np  # http://www.numpy.org\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from math import log, floor, ceil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Utility class's methods. You can also add additional methods as required but don't change existing methods' arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Utility(object):\n",
    "    \n",
    "    # This method computes entropy for information gain\n",
    "    def entropy(self, class_y):\n",
    "        entropy = 0\n",
    "        frequency = np.bincount(class_y)/len(class_y)\n",
    "        \n",
    "        for x in frequency:\n",
    "            if x>0:\n",
    "                entropy -= x*np.log2(x)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def partition_classes(self, X, y, split_attribute, split_val):\n",
    "        X_left = []\n",
    "        X_right = []\n",
    "\n",
    "        y_left = []\n",
    "        y_right = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if X[i][split_attribute] <= split_val:\n",
    "                X_left.append(X[i])\n",
    "                y_left.append(y[i])\n",
    "            \n",
    "            else: \n",
    "                X_right.append(X[i])\n",
    "                y_right.append(y[i])\n",
    "        \n",
    "        \n",
    "        return (X_left, X_right, y_left, y_right)\n",
    "\n",
    "\n",
    "    def information_gain(self, previous_y, current_y):\n",
    "        info_gain = 0\n",
    "        info_gain = self.entropy(previous_y)\n",
    "        \n",
    "        for split in range(len(current_y)):\n",
    "            info_gain -= (len(current_y[split])/len(previous_y)) * self.entropy(current_y[split])\n",
    "        \n",
    "        return info_gain\n",
    "\n",
    "\n",
    "    def best_split(self, X, y): \n",
    "        X_left, X_right, y_left, y_right = [], [], [], []\n",
    "\n",
    "        info_best_split = {}\n",
    "        current_best = 0\n",
    "\n",
    "        for col in range(len(X[0])): # This iterator accounts for the number of columns available in X\n",
    "            split_attribute = col  \n",
    "            column_values = sorted([x[col] for x in X])\n",
    "            \n",
    "            for val in column_values:    \n",
    "                split_val = val\n",
    "                X_left, X_right, y_left, y_right = self.partition_classes(X, y, split_attribute, split_val)\n",
    "                current_y = [y_left, y_right]\n",
    "                info_gain = self.information_gain(y, current_y)\n",
    "                \n",
    "                if info_gain > current_best: \n",
    "                    current_best = info_gain\n",
    "                    info_best_split = {\"best_split_feature\": split_attribute,\n",
    "                                       \"best_split_val\": split_val,\n",
    "                                       \"X_left\": X_left, \n",
    "                                       \"X_right\": X_right, \n",
    "                                       \"y_left\": y_left, \n",
    "                                       \"y_right\": y_right} \n",
    "\n",
    "         \n",
    "        return info_best_split\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classes 'DecisionTree' and 'RandomForest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please modify the 'DecisionTree' and 'RandomForest' classes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, max_depth):\n",
    "        # Initializing the tree as an empty dictionary or list, as preferred\n",
    "        self.tree = {}\n",
    "        self.max_depth = max_depth\n",
    "        self.util = Utility()\n",
    "        \n",
    "    def learn(self, X, y, par_node = {}, depth=0):\n",
    "        if len(X) == 0 or len(y) == 0:\n",
    "            self.tree[\"node_type\"] = \"fail_leaf\"\n",
    "            self.tree[\"node_value\"] = 0\n",
    "            return\n",
    "        \n",
    "        elif self.util.entropy(y)==0:\n",
    "            self.tree[\"node_type\"] = \"output_leaf\"\n",
    "            self.tree[\"node_value\"] = y[0]\n",
    "            return\n",
    "        \n",
    "        elif (depth == self.max_depth) or len(set(map(tuple, X))) == 1:\n",
    "            y = np.asarray(y)\n",
    "            self.tree[\"node_type\"] = \"output_leaf\"\n",
    "            self.tree[\"node_value\"] = np.bincount(y).argmax()\n",
    "            return\n",
    "        \n",
    "        best_split = self.util.best_split(X, y)\n",
    "               \n",
    "        self.tree['split_attr'] = best_split['best_split_feature'] \n",
    "        self.tree['split_val'] = best_split[\"best_split_val\"]\n",
    "        \n",
    "        self.tree[\"left_branch\"] = DecisionTree(max_depth=self.max_depth)   \n",
    "        self.tree[\"left_branch\"].learn(best_split[\"X_left\"],best_split[\"y_left\"], {}, depth+1)\n",
    "        \n",
    "        self.tree[\"right_branch\"] = DecisionTree(max_depth=self.max_depth)\n",
    "        self.tree[\"right_branch\"].learn(best_split[\"X_right\"], best_split[\"y_right\"], {}, depth+1)\n",
    "        \n",
    "        if len(self.tree[\"left_branch\"].tree) or len(self.tree[\"right_branch\"].tree) == 0:\n",
    "            self.tree[\"node_type\"] = \"fail_leaf\"\n",
    "            self.tree[\"node_value\"] = 0\n",
    "            return\n",
    "\n",
    "\n",
    "    def classify(self, record):\n",
    "        if self.tree[\"node_type\"] == \"output_leaf\":\n",
    "            return self.tree[\"node_value\"]\n",
    "        \n",
    "        attr = self.tree[\"split_attr\"]\n",
    "        val = self.tree[\"split_val\"]\n",
    "        \n",
    "        if record[attr] <= val: \n",
    "            return self.tree['left_branch'].classify(record)\n",
    "        else: \n",
    "            return self.tree['right_branch'].classify(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RandomForest(object):\n",
    "    num_trees = 0\n",
    "    decision_trees = []\n",
    "\n",
    "\n",
    "    bootstraps_datasets = []\n",
    "\n",
    "\n",
    "    bootstraps_labels = []\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        # Initialization done here\n",
    "        self.num_trees = num_trees\n",
    "        self.decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n",
    "        self.bootstraps_datasets = []\n",
    "        self.bootstraps_labels = []\n",
    "        \n",
    "    def _bootstrapping(self, XX, n):\n",
    "        # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n",
    "        #\n",
    "        # TODO: Create a sample dataset of size n by sampling with replacement\n",
    "        #       from the original dataset XX.\n",
    "        # Note that you would also need to record the corresponding class labels\n",
    "        # for the sampled records for training purposes.\n",
    "\n",
    "        sample = [] \n",
    "        labels = []  \n",
    "        \n",
    "        random_ind = random.sample(range(len(XX)), n)\n",
    "        \n",
    "        for i in random_ind: \n",
    "            sample.append(XX[i][:-1]) \n",
    "            labels.append(XX[i][-1]) \n",
    "\n",
    "        return (sample, labels)\n",
    "\n",
    "    def bootstrapping(self, XX):\n",
    "        # Initializing the bootstap datasets for each tree\n",
    "        for i in range(self.num_trees):\n",
    "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
    "            self.bootstraps_datasets.append(data_sample)\n",
    "            self.bootstraps_labels.append(data_label)\n",
    "\n",
    "    def fitting(self):\n",
    "         for num in range(self.num_trees):\n",
    "            self.decision_trees[num].learn(self.bootstraps_datasets[num], self.bootstraps_labels[num])\n",
    "\n",
    "    def voting(self, X):\n",
    "        y = []\n",
    "\n",
    "        for record in X:\n",
    "            # Following steps have been performed here:\n",
    "            #   1. Find the set of trees that consider the record as an\n",
    "            #      out-of-bag sample.\n",
    "            #   2. Predict the label using each of the above found trees.\n",
    "            #   3. Use majority vote to find the final label for this recod.\n",
    "            votes = []\n",
    "            for i in range(len(self.bootstraps_datasets)):\n",
    "                dataset = self.bootstraps_datasets[i]\n",
    "                \n",
    "                if record not in dataset:\n",
    "                    OOB_tree = self.decision_trees[i]\n",
    "                    effective_vote = OOB_tree.classify(record)\n",
    "                    votes.append(effective_vote)\n",
    "\n",
    "            counts = np.bincount(votes)\n",
    "        \n",
    "            if len(counts) == 0:\n",
    "                votes = [dt.classify(record) for dt in self.decision_trees]\n",
    "                y.append(np.bincount(votes).argmax())\n",
    "                \n",
    "            else:\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "                \n",
    "        return y\n",
    "\n",
    "    def user(self):\n",
    "        \"\"\"\n",
    "        :return: string\n",
    "        your GTUsername, NOT your 9-Digit GTId  \n",
    "        \"\"\"\n",
    "\n",
    "        return 'egrant37'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_forest_size():\n",
    "    forest_size = 10\n",
    "    return forest_size\n",
    "\n",
    "def get_random_seed():\n",
    "    random_seed = 0\n",
    "    return random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not modify the below cell\n",
    "The cell below is provided to test that your random forest classifier can be successfully built and run. Similar steps will be used to build and run your code in Gradescope. Any additional testing of functions can be done in the cells below the `%run helpers/notebook2script submission` cell, as these will not be parsed by the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    np.random.seed(get_random_seed())\n",
    "    # start time \n",
    "    start = datetime.now()\n",
    "    X = list()\n",
    "    y = list()\n",
    "    XX = list()  # Contains data features and data labels\n",
    "    numerical_cols = set([i for i in range(0, 31)])  # indices of numeric attributes (columns)\n",
    "\n",
    "    # Loading data set\n",
    "    print(\"reading the data\")\n",
    "    with open(\"Wisconsin_breast_prognostic.csv\") as f:\n",
    "        next(f, None)\n",
    "        for line in csv.reader(f, delimiter=\",\"):\n",
    "            xline = []\n",
    "            for i in range(len(line)):\n",
    "                if i in numerical_cols:\n",
    "                    xline.append(ast.literal_eval(line[i]))\n",
    "                else:\n",
    "                    xline.append(line[i])\n",
    "\n",
    "            X.append(xline[:-1])\n",
    "            y.append(xline[-1])\n",
    "            XX.append(xline[:])\n",
    "\n",
    "    # Initializing a random forest.\n",
    "    randomForest = RandomForest(get_forest_size())\n",
    "\n",
    "    # printing the name\n",
    "    print(\"__Name: \" + randomForest.user()+\"__\")\n",
    "\n",
    "    # Creating the bootstrapping datasets\n",
    "    print(\"creating the bootstrap datasets\")\n",
    "    randomForest.bootstrapping(XX)\n",
    "\n",
    "    # Building trees in the forest\n",
    "    print(\"fitting the forest\")\n",
    "    randomForest.fitting()\n",
    "\n",
    "    # Calculating an unbiased error estimation of the random forest\n",
    "    # based on out-of-bag (OOB) error estimate.\n",
    "    y_predicted = randomForest.voting(X)\n",
    "\n",
    "    # Comparing predicted and true labels\n",
    "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True)) / float(len(results))\n",
    "\n",
    "    print(\"accuracy: %.4f\" % accuracy)\n",
    "    print(\"OOB estimate: %.4f\" % (1 - accuracy))\n",
    "\n",
    "    # end time\n",
    "    print(\"Execution time: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the data\n",
      "__Name: egrant37__\n",
      "creating the bootstrap datasets\n",
      "fitting the forest\n",
      "accuracy: 1.0000\n",
      "OOB estimate: 0.0000\n",
      "Execution time: 0:01:05.666269\n"
     ]
    }
   ],
   "source": [
    "# Call the run() function to test your implementation\n",
    "# Use this cell and any cells below for additional testing\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf1e8345f3991e63f0377349612043dc62e53d2db35e0306b2f24fb858f18319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
